'use client'

import { useState, useRef, useEffect } from 'react'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar'
import { useAppStore } from '@/lib/store'
import { Send, Mic, MicOff, Smile, StopCircle, CheckCircle } from 'lucide-react'

interface Message {
  id: string
  content: string
  sender: 'user' | 'ai' | 'other'
  timestamp: Date
  type?: 'text' | 'voice' | 'image'
}

interface ChatInterfaceProps {
  matchId?: string
  isAIChat?: boolean
}

export function ChatInterface({ matchId, isAIChat = false }: ChatInterfaceProps) {
  const { language, user, authToken } = useAppStore()
  const [messages, setMessages] = useState<Message[]>([])
  const [inputText, setInputText] = useState('')
  const [isRecording, setIsRecording] = useState(false)
  const [isLoading, setIsLoading] = useState(false)
  const [isEndingConversation, setIsEndingConversation] = useState(false)
  const [conversationEnded, setConversationEnded] = useState(false)
  const [micPermission, setMicPermission] = useState<'granted' | 'denied' | 'prompt' | 'checking'>('checking')
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const recognitionRef = useRef<any>(null)
  const baseTextOnRecord = useRef('')
  const sessionIdRef = useRef<string>('')

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // ç”Ÿæˆä¼šè¯ID
  useEffect(() => {
    sessionIdRef.current = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }, [])

  // æ£€æŸ¥éº¦å…‹é£æƒé™ï¼ˆä»…åœ¨éAIèŠå¤©æ¨¡å¼ä¸‹ï¼‰
  useEffect(() => {
    if (isAIChat) return // AIèŠå¤©æ¨¡å¼ä¸éœ€è¦è¯­éŸ³åŠŸèƒ½
    
    const checkMicrophonePermission = async () => {
      try {
        if (navigator.permissions) {
          const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName })
          setMicPermission(permission.state as 'granted' | 'denied' | 'prompt')
          
          permission.onchange = () => {
            setMicPermission(permission.state as 'granted' | 'denied' | 'prompt')
          }
        } else {
          setMicPermission('prompt')
        }
      } catch (error) {
        console.error('Error checking microphone permission:', error)
        setMicPermission('prompt')
      }
    }

    checkMicrophonePermission()
  }, [isAIChat])

  useEffect(() => {
    if (isAIChat) return // AIèŠå¤©æ¨¡å¼ä¸éœ€è¦è¯­éŸ³è¯†åˆ«
    
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognition) {
      console.warn("Speech recognition not supported in this browser.")
      return
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = language === 'zh' ? 'zh-CN' : 'en-US'

    recognition.onresult = (event: any) => {
      let interimTranscript = ''
      let finalTranscript = ''
      
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        if (event.results[i].isFinal) {
          finalTranscript += event.results[i][0].transcript
        } else {
          interimTranscript += event.results[i][0].transcript
        }
      }
      
      setInputText(baseTextOnRecord.current + finalTranscript + interimTranscript)
    }

    recognition.onstart = () => {
      console.log('Speech recognition started')
      setMicPermission('granted')
    }

    recognition.onend = () => {
      console.log('Speech recognition ended')
      setIsRecording(false)
    }

    recognition.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error)
      setIsRecording(false)
      
      if (event.error === 'not-allowed' || event.error === 'permission-denied') {
        setMicPermission('denied')
      }
    }

    recognitionRef.current = recognition

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop()
      }
    }
  }, [language, isAIChat])

  // æ¨¡æ‹Ÿåˆå§‹æ¶ˆæ¯
  useEffect(() => {
    const initialMessages: Message[] = isAIChat ? [
      {
        id: '1',
        content: language === 'zh' 
          ? 'ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŒ¹é…åŠ©æ‰‹ã€‚è®©æˆ‘ä»¬å¼€å§‹äº†è§£ä½ çš„éœ€æ±‚å§ï¼'
          : 'Hello! I\'m your AI matching assistant. Let\'s start understanding your needs!',
        sender: 'ai',
        timestamp: new Date(),
        type: 'text'
      }
    ] : [
      {
        id: '1',
        content: language === 'zh' ? 'ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ä½ åŒ¹é…ï¼' : 'Hello! Nice to match with you!',
        sender: 'other',
        timestamp: new Date(),
        type: 'text'
      }
    ]
    setMessages(initialMessages)
  }, [isAIChat, language])

  // ä¿å­˜å¯¹è¯è®°å½•å¹¶ç”Ÿæˆæ ‡ç­¾
  const saveConversationAndGenerateTags = async (status: 'completed' | 'terminated') => {
    if (!user?.id) {
      console.error('User not logged in')
      return
    }

    try {
      setIsEndingConversation(true)
      
      // å‡†å¤‡å¯¹è¯å†å²æ•°æ®
      const conversationHistory = messages.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.content
      }))

      // è°ƒç”¨åç«¯APIä¿å­˜å¯¹è¯å¹¶ç”Ÿæˆæ ‡ç­¾
      const response = await fetch('/api/ai/conversation/save', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${authToken}`
        },
        body: JSON.stringify({
          history: conversationHistory,
          themeMode: 'romantic', // å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
          language: language,
          sessionId: sessionIdRef.current,
          status: status,
          triggerTagGeneration: true
        })
      })

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const result = await response.json()
      
      if (result.success) {
        console.log('å¯¹è¯ä¿å­˜æˆåŠŸ:', result)
        setConversationEnded(true)
        
        // æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
        const successMessage: Message = {
          id: `success_${Date.now()}`,
          content: language === 'zh' 
            ? `å¯¹è¯å·²ç»“æŸå¹¶ä¿å­˜ã€‚${result.data?.tag_generation?.success ? `æˆåŠŸç”Ÿæˆäº† ${result.data.tag_generation.generated_tags_count} ä¸ªæ ‡ç­¾ï¼` : 'æ ‡ç­¾ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚'}`
            : `Conversation ended and saved. ${result.data?.tag_generation?.success ? `Successfully generated ${result.data.tag_generation.generated_tags_count} tags!` : 'Tag generation failed, please try again later.'}`,
          sender: 'ai',
          timestamp: new Date(),
          type: 'text'
        }
        
        setMessages(prev => [...prev, successMessage])
      } else {
        throw new Error(result.message || 'Failed to save conversation')
      }
    } catch (error) {
      console.error('ä¿å­˜å¯¹è¯å¤±è´¥:', error)
      
      // æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
      const errorMessage: Message = {
        id: `error_${Date.now()}`,
        content: language === 'zh' 
          ? 'å¯¹è¯ä¿å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚'
          : 'Failed to save conversation, please try again later.',
        sender: 'ai',
        timestamp: new Date(),
        type: 'text'
      }
      
      setMessages(prev => [...prev, errorMessage])
    } finally {
      setIsEndingConversation(false)
    }
  }

  // æå‰ç»“æŸå¯¹è¯
  const handleEndConversation = async () => {
    if (conversationEnded) return
    
    const confirmEnd = window.confirm(
      language === 'zh' 
        ? 'ç¡®å®šè¦æå‰ç»“æŸå¯¹è¯å—ï¼Ÿå¯¹è¯è®°å½•å°†è¢«ä¿å­˜å¹¶ç”¨äºç”Ÿæˆä¸ªæ€§åŒ–æ ‡ç­¾ã€‚'
        : 'Are you sure you want to end the conversation early? The conversation will be saved and used to generate personalized tags.'
    )
    
    if (confirmEnd) {
      await saveConversationAndGenerateTags('terminated')
    }
  }

  const handleSendMessage = async () => {
    if (!inputText.trim() || conversationEnded) return

    const newMessage: Message = {
      id: Date.now().toString(),
      content: inputText,
      sender: 'user',
      timestamp: new Date(),
      type: 'text'
    }

    setMessages(prev => [...prev, newMessage])
    setInputText('')
    setIsLoading(true)

    // æ¨¡æ‹ŸAIæˆ–å…¶ä»–ç”¨æˆ·å›å¤
    setTimeout(() => {
      const response: Message = {
        id: (Date.now() + 1).toString(),
        content: isAIChat 
          ? (language === 'zh' 
              ? 'è®©æˆ‘åˆ†æä¸€ä¸‹ä½ çš„éœ€æ±‚ã€‚ä½ æ›´åå‘äºä»€ä¹ˆç±»å‹çš„åŒ¹é…å‘¢ï¼Ÿ'
              : 'Let me analyze your needs. What type of matching do you prefer?')
          : (language === 'zh' 
              ? 'æˆ‘ä¹Ÿå¾ˆæœŸå¾…æˆ‘ä»¬çš„åˆä½œï¼'
              : 'I\'m also looking forward to our collaboration!'),
        sender: isAIChat ? 'ai' : 'other',
        timestamp: new Date(),
        type: 'text'
      }
      setMessages(prev => [...prev, response])
      setIsLoading(false)
    }, 1000)
  }

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault()
      handleSendMessage()
    }
  }

  const requestMicrophonePermission = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      stream.getTracks().forEach(track => track.stop())
      setMicPermission('granted')
      return true
    } catch (error) {
      console.error('Microphone permission denied:', error)
      setMicPermission('denied')
      return false
    }
  }

  const toggleRecording = async () => {
    if (!recognitionRef.current) {
      console.warn("Speech recognition not available")
      return
    }

    if (isRecording) {
      recognitionRef.current.stop()
      setIsRecording(false)
    } else {
      if (micPermission === 'denied') {
        alert(language === 'zh' 
          ? 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®' 
          : 'Microphone permission denied. Please allow microphone access in browser settings')
        return
      }

      if (micPermission === 'prompt' || micPermission === 'checking') {
        const hasPermission = await requestMicrophonePermission()
        if (!hasPermission) {
          return
        }
      }

      baseTextOnRecord.current = inputText ? inputText + ' ' : ''
      try {
        recognitionRef.current.start()
        setIsRecording(true)
      } catch (error) {
        console.error('Failed to start speech recognition:', error)
        setIsRecording(false)
        
        if (error instanceof Error && error.message.includes('not-allowed')) {
          alert(language === 'zh' 
            ? 'éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½ä½¿ç”¨è¯­éŸ³è¾“å…¥åŠŸèƒ½' 
            : 'Microphone permission is required for voice input')
        }
      }
    }
  }

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString(language === 'zh' ? 'zh-CN' : 'en-US', {
      hour: '2-digit',
      minute: '2-digit'
    })
  }

  return (
    <div className="flex flex-col h-full max-h-[600px] border rounded-lg bg-background">
      {/* Chat Header */}
      <div className="border-b p-4">
        <div className="flex items-center space-x-3">
          <Avatar className="h-10 w-10">
            <AvatarImage src={isAIChat ? undefined : "/api/placeholder/40/40"} />
            <AvatarFallback>
              {isAIChat ? 'ğŸ¤–' : 'M'}
            </AvatarFallback>
          </Avatar>
          <div className="flex-1">
            <h3 className="font-semibold">
              {isAIChat 
                ? (language === 'zh' ? 'AIåŒ¹é…åŠ©æ‰‹' : 'AI Matching Assistant')
                : (language === 'zh' ? 'åŒ¹é…ç”¨æˆ·' : 'Matched User')
              }
            </h3>
            <p className="text-sm text-muted-foreground">
              {conversationEnded 
                ? (language === 'zh' ? 'å¯¹è¯å·²ç»“æŸ' : 'Conversation ended')
                : isAIChat 
                ? (language === 'zh' ? 'åœ¨çº¿ - å‡†å¤‡å¸®åŠ©ä½ ' : 'Online - Ready to help')
                : (language === 'zh' ? 'åœ¨çº¿' : 'Online')
              }
            </p>
          </div>
          {/* AIèŠå¤©æ¨¡å¼ä¸‹æ˜¾ç¤ºæå‰ç»“æŸæŒ‰é’® */}
          {isAIChat && !conversationEnded && (
            <Button
              variant="outline"
              size="sm"
              onClick={handleEndConversation}
              disabled={isEndingConversation}
              className="text-orange-600 hover:text-orange-700 hover:bg-orange-50"
            >
              {isEndingConversation ? (
                <>
                  <div className="w-4 h-4 border-2 border-orange-600 border-t-transparent rounded-full animate-spin mr-2" />
                  {language === 'zh' ? 'ä¿å­˜ä¸­...' : 'Saving...'}
                </>
              ) : (
                <>
                  <StopCircle className="h-4 w-4 mr-2" />
                  {language === 'zh' ? 'æå‰ç»“æŸ' : 'End Early'}
                </>
              )}
            </Button>
          )}
          {/* å¯¹è¯ç»“æŸåæ˜¾ç¤ºå®Œæˆæ ‡è¯† */}
          {isAIChat && conversationEnded && (
            <div className="flex items-center text-green-600">
              <CheckCircle className="h-4 w-4 mr-2" />
              <span className="text-sm font-medium">
                {language === 'zh' ? 'å·²å®Œæˆ' : 'Completed'}
              </span>
            </div>
          )}
        </div>
      </div>

      {/* Messages Area */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div className={`flex items-end space-x-2 max-w-[70%] ${
              message.sender === 'user' ? 'flex-row-reverse space-x-reverse' : ''
            }`}>
              {message.sender !== 'user' && (
                <Avatar className="h-8 w-8">
                  <AvatarFallback>
                    {message.sender === 'ai' ? 'ğŸ¤–' : 'M'}
                  </AvatarFallback>
                </Avatar>
              )}
              <div
                className={`rounded-lg px-3 py-2 ${
                  message.sender === 'user'
                    ? 'bg-primary text-primary-foreground'
                    : 'bg-muted'
                }`}
              >
                <p className="text-sm">{message.content}</p>
                <p className="text-xs opacity-70 mt-1">
                  {formatTime(message.timestamp)}
                </p>
              </div>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="flex justify-start">
            <div className="flex items-end space-x-2">
              <Avatar className="h-8 w-8">
                <AvatarFallback>
                  {isAIChat ? 'ğŸ¤–' : 'M'}
                </AvatarFallback>
              </Avatar>
              <div className="bg-muted rounded-lg px-3 py-2">
                <div className="flex space-x-1">
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce"></div>
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                </div>
              </div>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>

      {/* Input Area */}
      <div className="border-t p-4">
        <div className="flex items-center space-x-2">
          {/* åªåœ¨éAIèŠå¤©æ¨¡å¼ä¸‹æ˜¾ç¤ºéº¦å…‹é£æŒ‰é’® */}
          {!isAIChat && (
            <Button
              variant="ghost"
              size="icon"
              onClick={toggleRecording}
              disabled={micPermission === 'checking' || !recognitionRef.current}
              className={`${isRecording ? 'text-red-500' : ''} ${
                micPermission === 'denied' ? 'text-gray-400' : ''
              }`}
              title={
                micPermission === 'denied' 
                  ? (language === 'zh' ? 'éº¦å…‹é£æƒé™è¢«æ‹’ç»' : 'Microphone permission denied')
                  : micPermission === 'checking'
                  ? (language === 'zh' ? 'æ£€æŸ¥æƒé™ä¸­...' : 'Checking permission...')
                  : isRecording 
                  ? (language === 'zh' ? 'åœæ­¢å½•éŸ³' : 'Stop recording')
                  : (language === 'zh' ? 'å¼€å§‹è¯­éŸ³è¾“å…¥' : 'Start voice input')
              }
            >
              {isRecording ? <MicOff className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
            </Button>
          )}
          
          <div className="flex-1 relative">
            <Input
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder={conversationEnded 
                ? (language === 'zh' ? 'å¯¹è¯å·²ç»“æŸ' : 'Conversation ended')
                : (language === 'zh' ? 'è¾“å…¥æ¶ˆæ¯...' : 'Type a message...')
              }
              disabled={isLoading || conversationEnded}
            />
          </div>
          
          <Button
            variant="ghost"
            size="icon"
            disabled={conversationEnded}
          >
            <Smile className="h-4 w-4" />
          </Button>
          
          <Button
            onClick={handleSendMessage}
            disabled={!inputText.trim() || isLoading || conversationEnded}
            size="icon"
          >
            <Send className="h-4 w-4" />
          </Button>
        </div>
      </div>
    </div>
  )
} 