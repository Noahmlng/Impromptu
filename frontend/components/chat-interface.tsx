'use client'

import { useState, useRef, useEffect } from 'react'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar'
import { useAppStore } from '@/lib/store'
import { Send, Mic, MicOff, Smile } from 'lucide-react'

interface Message {
  id: string
  content: string
  sender: 'user' | 'ai' | 'other'
  timestamp: Date
  type?: 'text' | 'voice' | 'image'
}

interface ChatInterfaceProps {
  matchId?: string
  isAIChat?: boolean
}

export function ChatInterface({ matchId, isAIChat = false }: ChatInterfaceProps) {
  const { language, user } = useAppStore()
  const [messages, setMessages] = useState<Message[]>([])
  const [inputText, setInputText] = useState('')
  const [isRecording, setIsRecording] = useState(false)
  const [isLoading, setIsLoading] = useState(false)
  const [micPermission, setMicPermission] = useState<'granted' | 'denied' | 'prompt' | 'checking'>('checking')
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const recognitionRef = useRef<any>(null)
  const baseTextOnRecord = useRef('')

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // Ê£ÄÊü•È∫¶ÂÖãÈ£éÊùÉÈôê
  useEffect(() => {
    const checkMicrophonePermission = async () => {
      try {
        if (navigator.permissions) {
          const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName })
          setMicPermission(permission.state as 'granted' | 'denied' | 'prompt')
          
          permission.onchange = () => {
            setMicPermission(permission.state as 'granted' | 'denied' | 'prompt')
          }
        } else {
          // Â¶ÇÊûú‰∏çÊîØÊåÅÊùÉÈôêAPIÔºåËÆæÁΩÆ‰∏∫promptÁä∂ÊÄÅ
          setMicPermission('prompt')
        }
      } catch (error) {
        console.error('Error checking microphone permission:', error)
        setMicPermission('prompt')
      }
    }

    checkMicrophonePermission()
  }, [])

  useEffect(() => {
    // Ê£ÄÊü•ÊµèËßàÂô®ÊòØÂê¶ÊîØÊåÅËØ≠Èü≥ËØÜÂà´
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognition) {
      console.warn("Speech recognition not supported in this browser.")
      return
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = language === 'zh' ? 'zh-CN' : 'en-US'

    recognition.onresult = (event: any) => {
      let interimTranscript = ''
      let finalTranscript = ''
      
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        if (event.results[i].isFinal) {
          finalTranscript += event.results[i][0].transcript
        } else {
          interimTranscript += event.results[i][0].transcript
        }
      }
      
      // Êõ¥Êñ∞ËæìÂÖ•Ê°ÜÂÜÖÂÆπÔºöÂéüÊúâÊñáÊú¨ + ÊúÄÁªàËØÜÂà´ÁªìÊûú + ‰∏¥Êó∂ËØÜÂà´ÁªìÊûú
      setInputText(baseTextOnRecord.current + finalTranscript + interimTranscript)
    }

    recognition.onstart = () => {
      console.log('Speech recognition started')
      setMicPermission('granted') // ÊàêÂäüÂêØÂä®ËØ¥ÊòéÊùÉÈôêÂ∑≤Ëé∑Âæó
    }

    recognition.onend = () => {
      console.log('Speech recognition ended')
      setIsRecording(false)
    }

    recognition.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error)
      setIsRecording(false)
      
      // Â§ÑÁêÜÊùÉÈôêÁõ∏ÂÖ≥ÈîôËØØ
      if (event.error === 'not-allowed' || event.error === 'permission-denied') {
        setMicPermission('denied')
      }
    }

    recognitionRef.current = recognition

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop()
      }
    }
  }, [language])

  // Ê®°ÊãüÂàùÂßãÊ∂àÊÅØ
  useEffect(() => {
    const initialMessages: Message[] = isAIChat ? [
      {
        id: '1',
        content: language === 'zh' 
          ? '‰Ω†Â•ΩÔºÅÊàëÊòØ‰Ω†ÁöÑAIÂåπÈÖçÂä©Êâã„ÄÇËÆ©Êàë‰ª¨ÂºÄÂßã‰∫ÜËß£‰Ω†ÁöÑÈúÄÊ±ÇÂêßÔºÅ'
          : 'Hello! I\'m your AI matching assistant. Let\'s start understanding your needs!',
        sender: 'ai',
        timestamp: new Date(),
        type: 'text'
      }
    ] : [
      {
        id: '1',
        content: language === 'zh' ? '‰Ω†Â•ΩÔºÅÂæàÈ´òÂÖ¥‰∏é‰Ω†ÂåπÈÖçÔºÅ' : 'Hello! Nice to match with you!',
        sender: 'other',
        timestamp: new Date(),
        type: 'text'
      }
    ]
    setMessages(initialMessages)
  }, [isAIChat, language])

  const handleSendMessage = async () => {
    if (!inputText.trim()) return

    const newMessage: Message = {
      id: Date.now().toString(),
      content: inputText,
      sender: 'user',
      timestamp: new Date(),
      type: 'text'
    }

    setMessages(prev => [...prev, newMessage])
    setInputText('')
    setIsLoading(true)

    // Ê®°ÊãüAIÊàñÂÖ∂‰ªñÁî®Êà∑ÂõûÂ§ç
    setTimeout(() => {
      const response: Message = {
        id: (Date.now() + 1).toString(),
        content: isAIChat 
          ? (language === 'zh' 
              ? 'ËÆ©ÊàëÂàÜÊûê‰∏Ä‰∏ã‰Ω†ÁöÑÈúÄÊ±Ç„ÄÇ‰Ω†Êõ¥ÂÅèÂêë‰∫é‰ªÄ‰πàÁ±ªÂûãÁöÑÂåπÈÖçÂë¢Ôºü'
              : 'Let me analyze your needs. What type of matching do you prefer?')
          : (language === 'zh' 
              ? 'Êàë‰πüÂæàÊúüÂæÖÊàë‰ª¨ÁöÑÂêà‰ΩúÔºÅ'
              : 'I\'m also looking forward to our collaboration!'),
        sender: isAIChat ? 'ai' : 'other',
        timestamp: new Date(),
        type: 'text'
      }
      setMessages(prev => [...prev, response])
      setIsLoading(false)
    }, 1000)
  }

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault()
      handleSendMessage()
    }
  }

  const requestMicrophonePermission = async () => {
    try {
      // ÈÄöËøágetUserMediaËØ∑Ê±ÇÈ∫¶ÂÖãÈ£éÊùÉÈôê
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      // Á´ãÂç≥ÂÖ≥Èó≠ÊµÅÔºåÊàë‰ª¨Âè™ÈúÄË¶ÅÊùÉÈôê
      stream.getTracks().forEach(track => track.stop())
      setMicPermission('granted')
      return true
    } catch (error) {
      console.error('Microphone permission denied:', error)
      setMicPermission('denied')
      return false
    }
  }

  const toggleRecording = async () => {
    if (!recognitionRef.current) {
      console.warn("Speech recognition not available")
      return
    }

    if (isRecording) {
      // ÂÅúÊ≠¢ÂΩïÈü≥
      recognitionRef.current.stop()
      setIsRecording(false)
    } else {
      // Ê£ÄÊü•ÊùÉÈôêÁä∂ÊÄÅ
      if (micPermission === 'denied') {
        alert(language === 'zh' 
          ? 'È∫¶ÂÖãÈ£éÊùÉÈôêË¢´ÊãíÁªùÔºåËØ∑Âú®ÊµèËßàÂô®ËÆæÁΩÆ‰∏≠ÂÖÅËÆ∏È∫¶ÂÖãÈ£éËÆøÈóÆ' 
          : 'Microphone permission denied. Please allow microphone access in browser settings')
        return
      }

      // Â¶ÇÊûúÊùÉÈôêÊú™Áü•ÊàñÈúÄË¶ÅÁî≥ËØ∑ÔºåÂÖàËØ∑Ê±ÇÊùÉÈôê
      if (micPermission === 'prompt' || micPermission === 'checking') {
        const hasPermission = await requestMicrophonePermission()
        if (!hasPermission) {
          return
        }
      }

      // ÂºÄÂßãÂΩïÈü≥Ââç‰øùÂ≠òÂΩìÂâçËæìÂÖ•ÁöÑÊñáÊú¨
      baseTextOnRecord.current = inputText ? inputText + ' ' : ''
      try {
        recognitionRef.current.start()
        setIsRecording(true)
      } catch (error) {
        console.error('Failed to start speech recognition:', error)
        setIsRecording(false)
        
        // Â¶ÇÊûúÊòØÊùÉÈôêÈîôËØØÔºåÊèêÁ§∫Áî®Êà∑
        if (error instanceof Error && error.message.includes('not-allowed')) {
          alert(language === 'zh' 
            ? 'ÈúÄË¶ÅÈ∫¶ÂÖãÈ£éÊùÉÈôêÊâçËÉΩ‰ΩøÁî®ËØ≠Èü≥ËæìÂÖ•ÂäüËÉΩ' 
            : 'Microphone permission is required for voice input')
        }
      }
    }
  }

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString(language === 'zh' ? 'zh-CN' : 'en-US', {
      hour: '2-digit',
      minute: '2-digit'
    })
  }

  return (
    <div className="flex flex-col h-full max-h-[600px] border rounded-lg bg-background">
      {/* Chat Header */}
      <div className="border-b p-4">
        <div className="flex items-center space-x-3">
          <Avatar className="h-10 w-10">
            <AvatarImage src={isAIChat ? undefined : "/api/placeholder/40/40"} />
            <AvatarFallback>
              {isAIChat ? 'ü§ñ' : 'M'}
            </AvatarFallback>
          </Avatar>
          <div className="flex-1">
            <h3 className="font-semibold">
              {isAIChat 
                ? (language === 'zh' ? 'AIÂåπÈÖçÂä©Êâã' : 'AI Matching Assistant')
                : (language === 'zh' ? 'ÂåπÈÖçÁî®Êà∑' : 'Matched User')
              }
            </h3>
            <p className="text-sm text-muted-foreground">
              {isAIChat 
                ? (language === 'zh' ? 'Âú®Á∫ø - ÂáÜÂ§áÂ∏ÆÂä©‰Ω†' : 'Online - Ready to help')
                : (language === 'zh' ? 'Âú®Á∫ø' : 'Online')
              }
            </p>
          </div>
        </div>
      </div>

      {/* Messages Area */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div className={`flex items-end space-x-2 max-w-[70%] ${
              message.sender === 'user' ? 'flex-row-reverse space-x-reverse' : ''
            }`}>
              {message.sender !== 'user' && (
                <Avatar className="h-8 w-8">
                  <AvatarFallback>
                    {message.sender === 'ai' ? 'ü§ñ' : 'M'}
                  </AvatarFallback>
                </Avatar>
              )}
              <div
                className={`rounded-lg px-3 py-2 ${
                  message.sender === 'user'
                    ? 'bg-primary text-primary-foreground'
                    : 'bg-muted'
                }`}
              >
                <p className="text-sm">{message.content}</p>
                <p className="text-xs opacity-70 mt-1">
                  {formatTime(message.timestamp)}
                </p>
              </div>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="flex justify-start">
            <div className="flex items-end space-x-2">
              <Avatar className="h-8 w-8">
                <AvatarFallback>
                  {isAIChat ? 'ü§ñ' : 'M'}
                </AvatarFallback>
              </Avatar>
              <div className="bg-muted rounded-lg px-3 py-2">
                <div className="flex space-x-1">
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce"></div>
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                  <div className="w-2 h-2 bg-current rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                </div>
              </div>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>

      {/* Input Area */}
      <div className="border-t p-4">
        <div className="flex items-center space-x-2">
          <Button
            variant="ghost"
            size="icon"
            onClick={toggleRecording}
            disabled={micPermission === 'checking' || !recognitionRef.current}
            className={`${isRecording ? 'text-red-500' : ''} ${
              micPermission === 'denied' ? 'text-gray-400' : ''
            }`}
            title={
              micPermission === 'denied' 
                ? (language === 'zh' ? 'È∫¶ÂÖãÈ£éÊùÉÈôêË¢´ÊãíÁªù' : 'Microphone permission denied')
                : micPermission === 'checking'
                ? (language === 'zh' ? 'Ê£ÄÊü•ÊùÉÈôê‰∏≠...' : 'Checking permission...')
                : isRecording 
                ? (language === 'zh' ? 'ÂÅúÊ≠¢ÂΩïÈü≥' : 'Stop recording')
                : (language === 'zh' ? 'ÂºÄÂßãËØ≠Èü≥ËæìÂÖ•' : 'Start voice input')
            }
          >
            {isRecording ? <MicOff className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
          </Button>
          
          <div className="flex-1 relative">
            <Input
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder={language === 'zh' ? 'ËæìÂÖ•Ê∂àÊÅØ...' : 'Type a message...'}
              disabled={isLoading}
            />
          </div>
          
          <Button
            variant="ghost"
            size="icon"
          >
            <Smile className="h-4 w-4" />
          </Button>
          
          <Button
            onClick={handleSendMessage}
            disabled={!inputText.trim() || isLoading}
            size="icon"
          >
            <Send className="h-4 w-4" />
          </Button>
        </div>
      </div>
    </div>
  )
} 