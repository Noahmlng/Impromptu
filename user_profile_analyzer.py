#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç”¨æˆ·ç”»åƒåˆ†æžå™¨ - åŸºäºŽé¢„å®šä¹‰æ ‡ç­¾æ± çš„æ–‡æœ¬åˆ†æžç³»ç»Ÿ

è¿™ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒç†å¿µæ˜¯ï¼š
1. ä¸éœ€è¦å¤æ‚çš„LDAè®­ç»ƒè¿‡ç¨‹
2. ç›´æŽ¥åŸºäºŽé¢„å®šä¹‰æ ‡ç­¾æ± è¿›è¡ŒåŒ¹é…
3. ä½¿ç”¨å¤šç§åŒ¹é…ç­–ç•¥æé«˜å‡†ç¡®çŽ‡
4. é€‚ç”¨äºŽä½ çš„"æ‰¾å¯¹è±¡"å’Œ"æ‰¾é˜Ÿå‹"åœºæ™¯
"""

import json
import os
from typing import Dict, List, Any
from dataclasses import dataclass, asdict
from models.tag_matching import TagMatcher, TagMatchResult

@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    request_type: str  # "æ‰¾å¯¹è±¡" æˆ– "æ‰¾é˜Ÿå‹"
    original_text: str
    extracted_tags: Dict[str, float]
    tag_categories: Dict[str, List[tuple]]  # åºåˆ—åŒ–å‹å¥½çš„æ ¼å¼
    total_score: float
    profile_completeness: float  # ç”»åƒå®Œæ•´åº¦ 0-1

class UserProfileAnalyzer:
    """ç”¨æˆ·ç”»åƒåˆ†æžå™¨"""
    
    def __init__(self):
        # ä¸ºä¸åŒåœºæ™¯åˆ›å»ºä¸“é—¨çš„åŒ¹é…å™¨
        self.dating_matcher = TagMatcher("æ‰¾å¯¹è±¡")
        self.teamwork_matcher = TagMatcher("æ‰¾é˜Ÿå‹")
        
        # å­˜å‚¨è·¯å¾„
        self.profiles_dir = "data/user_profiles"
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(self.profiles_dir, exist_ok=True)
    
    def analyze_user(self, user_id: str, user_text: str, request_type: str) -> UserProfile:
        """åˆ†æžå•ä¸ªç”¨æˆ·å¹¶ç”Ÿæˆç”»åƒ"""
        
        # é€‰æ‹©å¯¹åº”çš„åŒ¹é…å™¨
        if request_type == "æ‰¾å¯¹è±¡":
            matcher = self.dating_matcher
        elif request_type == "æ‰¾é˜Ÿå‹":
            matcher = self.teamwork_matcher
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯·æ±‚ç±»åž‹: {request_type}")
        
        # è¿›è¡Œæ ‡ç­¾åŒ¹é…
        result = matcher.match_tags(user_text, min_confidence=0.3)
        
        # è®¡ç®—ç”»åƒå®Œæ•´åº¦
        completeness = self._calculate_completeness(result, request_type)
        
        # è½¬æ¢tag_categoriesä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        serializable_categories = {}
        for category, tags in result.tag_categories.items():
            serializable_categories[category.value] = tags
        
        # åˆ›å»ºç”¨æˆ·ç”»åƒ
        profile = UserProfile(
            user_id=user_id,
            request_type=request_type,
            original_text=user_text,
            extracted_tags=result.matched_tags,
            tag_categories=serializable_categories,
            total_score=result.total_score,
            profile_completeness=completeness
        )
        
        return profile
    
    def _calculate_completeness(self, result: TagMatchResult, request_type: str) -> float:
        """è®¡ç®—ç”»åƒå®Œæ•´åº¦"""
        if request_type == "æ‰¾å¯¹è±¡":
            # æ‰¾å¯¹è±¡éœ€è¦çš„å…³é”®ç»´åº¦
            required_categories = ["age", "profession", "personality", "interests", "location"]
        else:
            # æ‰¾é˜Ÿå‹éœ€è¦çš„å…³é”®ç»´åº¦
            required_categories = ["skills", "experience_level", "project_type", "availability"]
        
        covered_categories = set()
        for category_name in result.tag_categories.keys():
            if category_name.value in required_categories:
                covered_categories.add(category_name.value)
        
        return len(covered_categories) / len(required_categories)
    
    def batch_analyze_users(self, users_data: List[Dict[str, Any]]) -> List[UserProfile]:
        """æ‰¹é‡åˆ†æžç”¨æˆ·"""
        profiles = []
        
        for user_data in users_data:
            user_id = user_data["user_id"]
            user_text = user_data["text"]
            request_type = user_data["request_type"]
            
            try:
                profile = self.analyze_user(user_id, user_text, request_type)
                profiles.append(profile)
                print(f"âœ… æˆåŠŸåˆ†æžç”¨æˆ· {user_id}")
            except Exception as e:
                print(f"âŒ åˆ†æžç”¨æˆ· {user_id} æ—¶å‡ºé”™: {e}")
        
        return profiles
    
    def save_profile(self, profile: UserProfile) -> None:
        """ä¿å­˜ç”¨æˆ·ç”»åƒåˆ°æ–‡ä»¶"""
        filename = f"{profile.user_id}_{profile.request_type}_profile.json"
        filepath = os.path.join(self.profiles_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(asdict(profile), f, ensure_ascii=False, indent=2)
        
        print(f"ç”»åƒå·²ä¿å­˜: {filepath}")
    
    def load_profile(self, user_id: str, request_type: str) -> UserProfile:
        """ä»Žæ–‡ä»¶åŠ è½½ç”¨æˆ·ç”»åƒ"""
        filename = f"{user_id}_{request_type}_profile.json"
        filepath = os.path.join(self.profiles_dir, filename)
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return UserProfile(**data)
    
    def find_similar_users(self, target_profile: UserProfile, 
                          candidate_profiles: List[UserProfile], 
                          top_k: int = 5) -> List[tuple]:
        """æ‰¾åˆ°ç›¸ä¼¼çš„ç”¨æˆ·"""
        similarities = []
        
        for candidate in candidate_profiles:
            if candidate.request_type != target_profile.request_type:
                continue
            
            # è®¡ç®—æ ‡ç­¾é‡å ç›¸ä¼¼åº¦
            similarity = self._calculate_tag_similarity(
                target_profile.extracted_tags, 
                candidate.extracted_tags
            )
            
            similarities.append((candidate.user_id, similarity, candidate))
        
        # æŒ‰ç›¸ä¼¼åº¦æŽ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def _calculate_tag_similarity(self, tags1: Dict[str, float], 
                                 tags2: Dict[str, float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ ‡ç­¾é›†åˆçš„ç›¸ä¼¼åº¦"""
        if not tags1 or not tags2:
            return 0.0
        
        # è®¡ç®—æ ‡ç­¾äº¤é›†çš„æƒé‡å’Œ
        common_tags = set(tags1.keys()) & set(tags2.keys())
        if not common_tags:
            return 0.0
        
        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = sum(tags1[tag] * tags2[tag] for tag in common_tags)
        norm1 = sum(score ** 2 for score in tags1.values()) ** 0.5
        norm2 = sum(score ** 2 for score in tags2.values()) ** 0.5
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def generate_profile_summary(self, profile: UserProfile) -> str:
        """ç”Ÿæˆç”»åƒæ‘˜è¦"""
        summary = f"""
ç”¨æˆ·ç”»åƒæ‘˜è¦ - {profile.user_id}
================================
è¯·æ±‚ç±»åž‹: {profile.request_type}
ç”»åƒå®Œæ•´åº¦: {profile.profile_completeness:.1%}
æ€»ä½“åŒ¹é…åˆ†æ•°: {profile.total_score:.2f}

æå–çš„æ ‡ç­¾:
"""
        
        for category_name, tags in profile.tag_categories.items():
            if tags:
                summary += f"\nã€{category_name}ã€‘\n"
                for tag, score in tags[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæœ€ç›¸å…³çš„æ ‡ç­¾
                    summary += f"  â€¢ {tag} (ç½®ä¿¡åº¦: {score:.2f})\n"
        
        return summary

def demonstration_example():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç”¨æˆ·ç”»åƒåˆ†æžå™¨"""
    
    print("ðŸŽ¯ ç”¨æˆ·ç”»åƒåˆ†æžå™¨æ¼”ç¤º")
    print("=" * 50)
    
    analyzer = UserProfileAnalyzer()
    
    # æ¨¡æ‹Ÿç”¨æˆ·æ•°æ®
    sample_users = [
        {
            "user_id": "user_001",
            "request_type": "æ‰¾å¯¹è±¡",
            "text": """
            æˆ‘æ˜¯ä¸€ä¸ª28å²çš„äº§å“ç»ç†ï¼Œåœ¨åŒ—äº¬å·¥ä½œã€‚æ€§æ ¼æ¯”è¾ƒå¤–å‘ï¼Œ
            å–œæ¬¢å’Œæœ‹å‹èšä¼šï¼Œå‘¨æœ«ç»å¸¸åŽ»å¥èº«æˆ¿é”»ç‚¼ï¼Œä¹Ÿå–œæ¬¢æ—…è¡Œå’Œæ‘„å½±ã€‚
            å¸Œæœ›æ‰¾ä¸€ä¸ªæœ‰å…±åŒå…´è¶£çˆ±å¥½ï¼Œæ€§æ ¼å¼€æœ—çš„å¥³ç”Ÿä¸€èµ·ç”Ÿæ´»ã€‚
            """
        },
        {
            "user_id": "user_002", 
            "request_type": "æ‰¾é˜Ÿå‹",
            "text": """
            æˆ‘æ˜¯ä¸€ä¸ªæœ‰5å¹´ç»éªŒçš„å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆï¼Œæ“…é•¿Reactã€Node.jså’ŒPythonã€‚
            æƒ³æ‰¾æŠ€æœ¯åˆä¼™äººä¸€èµ·åšä¸€ä¸ªSaaSäº§å“ï¼Œä¸»è¦é¢å‘ä¸­å°ä¼ä¸šã€‚
            å¸Œæœ›èƒ½å¤Ÿé•¿æœŸåˆä½œï¼Œå¯ä»¥è¿œç¨‹å·¥ä½œï¼Œä½†æœ€å¥½åœ¨ä¸Šæµ·ã€‚
            """
        },
        {
            "user_id": "user_003",
            "request_type": "æ‰¾å¯¹è±¡", 
            "text": """
            25å²ç¨‹åºå‘˜ï¼Œæ¯”è¾ƒå†…å‘ï¼Œå–œæ¬¢çœ‹ä¹¦ã€æ‰“æ¸¸æˆã€å¬éŸ³ä¹ã€‚
            å·¥ä½œåœ¨æ·±åœ³ï¼Œå¸Œæœ›æ‰¾ä¸€ä¸ªç†è§£æˆ‘å·¥ä½œæ€§è´¨çš„å¥³ç”Ÿï¼Œ
            ä¸€èµ·è¿½å‰§ã€å¶å°”å‡ºåŽ»æ—…è¡Œå°±å¾ˆæ»¡è¶³äº†ã€‚
            """
        }
    ]
    
    # æ‰¹é‡åˆ†æžç”¨æˆ·
    print("ðŸ” å¼€å§‹æ‰¹é‡åˆ†æžç”¨æˆ·...")
    profiles = analyzer.batch_analyze_users(sample_users)
    
    # å±•ç¤ºåˆ†æžç»“æžœ
    for i, profile in enumerate(profiles, 1):
        print(f"\nðŸ“Š ç”¨æˆ· {i} åˆ†æžç»“æžœ:")
        print(analyzer.generate_profile_summary(profile))
        
        # ä¿å­˜ç”»åƒï¼ˆå¯é€‰ï¼‰
        # analyzer.save_profile(profile)
    
    # æ¼”ç¤ºæ‰¾ç›¸ä¼¼ç”¨æˆ·
    if len(profiles) >= 2:
        print("\nðŸ”— å¯»æ‰¾ç›¸ä¼¼ç”¨æˆ·:")
        target_user = profiles[0]
        other_users = profiles[1:]
        
        similar_users = analyzer.find_similar_users(target_user, other_users, top_k=2)
        
        print(f"ä¸Žç”¨æˆ· {target_user.user_id} æœ€ç›¸ä¼¼çš„ç”¨æˆ·:")
        for user_id, similarity, _ in similar_users:
            print(f"  â€¢ {user_id}: ç›¸ä¼¼åº¦ {similarity:.3f}")

if __name__ == "__main__":
    demonstration_example() 