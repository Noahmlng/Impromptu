# backend/services/ai_service.py

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict
import openai
import os
from dotenv import load_dotenv

from backend.prompts.prompts import get_system_prompt, get_analysis_prompt

# Load environment variables from .env file
load_dotenv()

router = APIRouter()

# Configure OpenAI client - è®©API Keyå˜ä¸ºå¯é€‰
openai.api_key = os.getenv("OPENAI_API_KEY")

# æ£€æŸ¥API KeyçŠ¶æ€ä½†ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨
OPENAI_AVAILABLE = bool(openai.api_key)
if not OPENAI_AVAILABLE:
    print("âš ï¸ OPENAI_API_KEY æœªè®¾ç½®ï¼ŒAIèŠå¤©åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("ğŸ’¡ å¦‚éœ€ä½¿ç”¨AIåŠŸèƒ½ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡: OPENAI_API_KEY=your_key")

class ChatRequest(BaseModel):
    message: Optional[str]
    history: List[Dict[str, str]]
    themeMode: str = 'romantic'
    language: str = 'en'
    isAnalysis: bool = False

@router.post("/chat")
async def handle_chat(request: ChatRequest):
    """
    Handles AI chat requests by proxying them to OpenAI.
    """
    # æ£€æŸ¥API Keyæ˜¯å¦å¯ç”¨
    if not OPENAI_AVAILABLE:
        raise HTTPException(
            status_code=503, 
            detail={
                "error": "AIæœåŠ¡ä¸å¯ç”¨",
                "message": "OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®",
                "solution": "è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡åé‡å¯åº”ç”¨"
            }
        )
    
    try:
        if request.isAnalysis:
            system_prompt = get_analysis_prompt(request.themeMode, request.language)
            # For analysis, the user message is often empty, history is the main context
            user_messages = request.history
            messages = [{"role": "system", "content": system_prompt}] + user_messages
        else:
            system_prompt = get_system_prompt(request.themeMode, request.language, len(request.history))
            user_messages = request.history
            messages = [{"role": "system", "content": system_prompt}] + user_messages
            if request.message:
                messages.append({"role": "user", "content": request.message})
        
        completion = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=1500 if request.isAnalysis else 1000,
            temperature=0.7,
            response_format={"type": "json_object"} if request.isAnalysis else None,
        )

        response_content = completion.choices[0].message.content
        return {"response": response_content}

    except openai.APIError as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

# æ·»åŠ AIæœåŠ¡çŠ¶æ€æ£€æŸ¥è·¯ç”±
@router.get("/status")
async def ai_service_status():
    """æ£€æŸ¥AIæœåŠ¡çŠ¶æ€"""
    return {
        "openai_available": OPENAI_AVAILABLE,
        "status": "ready" if OPENAI_AVAILABLE else "unavailable",
        "message": "AIæœåŠ¡æ­£å¸¸" if OPENAI_AVAILABLE else "éœ€è¦è®¾ç½® OPENAI_API_KEY"
    } 