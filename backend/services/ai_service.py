# backend/services/ai_service.py

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Optional, Dict
from openai import OpenAI
import os
from dotenv import load_dotenv
import logging
import uuid

from backend.prompts.prompts import get_system_prompt, get_analysis_prompt, get_initial_prompts
from backend.services.database_service import conversation_db
from backend.services.auth_service import get_current_user

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables from .env file
load_dotenv()

router = APIRouter()

# Configure OpenAI client
openai_api_key = os.getenv("OPENAI_API_KEY")
openai_base_url = os.getenv("OPENAI_BASE_URL")
moonshot_api_key = os.getenv("MOONSHOT_API_KEY")
moonshot_base_url = os.getenv("MOONSHOT_BASE_URL")

if not openai_api_key:
    logger.error("OPENAI_API_KEY environment variable not set!")
    raise ValueError("OPENAI_API_KEY environment variable not set.")

# client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)
client = OpenAI(api_key=moonshot_api_key, base_url=moonshot_base_url)
logger.info("OpenAI client initialized successfully")

class ChatRequest(BaseModel):
    message: Optional[str]
    history: List[Dict[str, str]]
    themeMode: str = 'romantic'
    language: str = 'en'
    isAnalysis: bool = False
    sessionId: Optional[str] = None

class SaveConversationRequest(BaseModel):
    history: List[Dict[str, str]]
    themeMode: str = 'romantic'
    language: str = 'zh'
    sessionId: Optional[str] = None
    status: str = 'completed'  # 'completed' or 'terminated'
    triggerTagGeneration: bool = True

class ConversationResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict] = None

@router.post("/chat")
async def handle_chat(request: ChatRequest):
    """
    Handles AI chat requests by proxying them to OpenAI.
    """
    try:
        logger.info(f"Received chat request: themeMode={request.themeMode}, language={request.language}, isAnalysis={request.isAnalysis}")
        logger.info(f"History length: {len(request.history)}")
        
        # åˆå§‹å¯¹è¯å¼•å¯¼
        initial_prompts = []
        if len(request.history) == 0 and not request.isAnalysis:
            logger.info("This is a new conversation. Adding initial prompts.")
            initial_prompts = get_initial_prompts(request.themeMode, request.language)

        if request.isAnalysis:
            logger.info("Processing analysis request")
            system_prompt = get_analysis_prompt(request.themeMode, request.language)
            # For analysis, the user message is often empty, history is the main context
            user_messages = request.history
            messages = [{"role": "system", "content": system_prompt}] + user_messages
        else:
            logger.info("Processing regular chat request")
            system_prompt = get_system_prompt(request.themeMode, request.language, len(request.history))
            user_messages = request.history
            messages = [{"role": "system", "content": system_prompt}] + initial_prompts + user_messages
            if request.message:
                messages.append({"role": "user", "content": request.message})
        
        logger.info(f"Prepared {len(messages)} messages for OpenAI")
        logger.debug(f"System prompt: {system_prompt[:100]}...")
        
        completion = client.chat.completions.create(
            # model="gpt-4.1-mini",
            model = "kimi-k2-0711-preview",
            messages=messages,
            max_tokens=1500 if request.isAnalysis else 1000,
            # temperature=0.7,
            temperature=0.6,
            response_format={"type": "json_object"} if request.isAnalysis else None,
        )

        response_content = completion.choices[0].message.content
        logger.info("Successfully received response from OpenAI")
        return {"response": response_content}

    except Exception as e:
        logger.error(f"Error in handle_chat: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router.post("/conversation/save", response_model=ConversationResponse)
async def save_conversation(
    request: SaveConversationRequest,
    current_user: Dict = Depends(get_current_user)
):
    """ä¿å­˜å¯¹è¯è®°å½•å¹¶å¯é€‰æ‹©è§¦å‘æ ‡ç­¾ç”Ÿæˆ"""
    try:
        user_id = current_user['user_id']
        logger.info(f"ğŸ’¬ ä¿å­˜ç”¨æˆ· {user_id} çš„å¯¹è¯è®°å½•ï¼ŒçŠ¶æ€: {request.status}")
        
        # ç”Ÿæˆsession_idå¦‚æœæ²¡æœ‰æä¾›
        session_id = request.sessionId or str(uuid.uuid4())
        
        # ä¿å­˜å¯¹è¯è®°å½•
        conversation_data = {
            'theme_mode': request.themeMode,
            'language': request.language,
            'history': request.history,
            'session_id': session_id,
            'status': request.status
        }
        
        saved_conversation = await conversation_db.save_conversation(user_id, conversation_data)
        
        if not saved_conversation:
            raise HTTPException(status_code=500, detail="ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥")
        
        result_data = {
            "conversation_id": saved_conversation.get('id'),
            "session_id": session_id,
            "message_count": len(request.history),
            "status": request.status
        }
        
        # å¦‚æœè¯·æ±‚è§¦å‘æ ‡ç­¾ç”Ÿæˆ
        if request.triggerTagGeneration:
            try:
                # å¯¼å…¥æ ‡ç­¾æœåŠ¡
                from backend.services.tag_service import generate_user_tags_with_conversation, GenerateTagsRequest
                
                # åˆ›å»ºæ ‡ç­¾ç”Ÿæˆè¯·æ±‚
                tag_request = GenerateTagsRequest(
                    request_type=request.themeMode,
                    include_conversation=True
                )
                
                # ç”Ÿæˆæ ‡ç­¾
                tag_result = await generate_user_tags_with_conversation(tag_request, current_user)
                
                result_data["tag_generation"] = {
                    "success": tag_result.success,
                    "message": tag_result.message,
                    "generated_tags_count": len(tag_result.data.get("generated_tags", [])) if tag_result.data else 0
                }
                
                logger.info(f"âœ… å¯¹è¯è®°å½•ä¿å­˜æˆåŠŸï¼Œå¹¶è§¦å‘äº†æ ‡ç­¾ç”Ÿæˆ")
                
            except Exception as tag_error:
                logger.error(f"âš ï¸ æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {tag_error}")
                result_data["tag_generation"] = {
                    "success": False,
                    "message": f"æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {str(tag_error)}",
                    "generated_tags_count": 0
                }
        
        return ConversationResponse(
            success=True,
            message="å¯¹è¯è®°å½•ä¿å­˜æˆåŠŸ" + ("ï¼Œå¹¶å·²è§¦å‘æ ‡ç­¾ç”Ÿæˆ" if request.triggerTagGeneration else ""),
            data=result_data
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¿å­˜å¯¹è¯è®°å½•é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥: {str(e)}")

@router.post("/conversation/end-and-generate-tags", response_model=ConversationResponse)
async def end_conversation_and_generate_tags(
    request: SaveConversationRequest,
    current_user: Dict = Depends(get_current_user)
):
    """ç»“æŸå¯¹è¯å¹¶ç”Ÿæˆæ ‡ç­¾çš„ä¾¿æ·æ¥å£"""
    # è®¾ç½®çŠ¶æ€ä¸ºcompletedå¹¶è§¦å‘æ ‡ç­¾ç”Ÿæˆ
    request.status = 'completed'
    request.triggerTagGeneration = True
    
    return await save_conversation(request, current_user)

@router.get("/conversation/history")
async def get_conversation_history(
    limit: int = 10,
    current_user: Dict = Depends(get_current_user)
):
    """è·å–ç”¨æˆ·çš„å¯¹è¯å†å²"""
    try:
        user_id = current_user['user_id']
        conversations = await conversation_db.get_user_conversations(user_id, limit)
        
        return {
            "success": True,
            "data": {
                "conversations": conversations,
                "total": len(conversations)
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯å†å²é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}") 

"""
ä½¿ç”¨ç¤ºä¾‹ï¼š

1. æ­£å¸¸å¯¹è¯æµç¨‹ï¼š
   POST /api/ai/chat
   {
     "message": "ä½ å¥½",
     "history": [],
     "themeMode": "romantic",
     "language": "zh",
     "sessionId": "session_123"
   }

2. ä¿å­˜å¯¹è¯è®°å½•å¹¶ç”Ÿæˆæ ‡ç­¾ï¼š
   POST /api/ai/conversation/save
   {
     "history": [
       {"role": "user", "content": "æˆ‘å–œæ¬¢éŸ³ä¹å’Œæ—…è¡Œ"},
       {"role": "assistant", "content": "å¾ˆæ£’ï¼ä½ æœ€å–œæ¬¢ä»€ä¹ˆç±»å‹çš„éŸ³ä¹ï¼Ÿ"}
     ],
     "themeMode": "romantic",
     "language": "zh",
     "sessionId": "session_123",
     "status": "completed",
     "triggerTagGeneration": true
   }

3. ä¾¿æ·çš„ç»“æŸå¯¹è¯å¹¶ç”Ÿæˆæ ‡ç­¾ï¼š
   POST /api/ai/conversation/end-and-generate-tags
   {
     "history": [...],
     "themeMode": "romantic",
     "language": "zh",
     "sessionId": "session_123"
   }

4. ç›´æ¥åŸºäºå¯¹è¯è®°å½•ç”Ÿæˆæ ‡ç­¾ï¼š
   POST /api/tags/generate/with-conversation
   {
     "request_type": "romantic",
     "include_conversation": true
   }

å¯¹è¯è®°å½•å°†è‡ªåŠ¨å­˜å‚¨åˆ°æ•°æ®åº“ä¸­ï¼Œå¹¶å¯ä»¥ç”¨äºæ ‡ç­¾ç”Ÿæˆï¼Œæé«˜æ ‡ç­¾çš„å‡†ç¡®æ€§å’Œä¸ªæ€§åŒ–ç¨‹åº¦ã€‚
""" 