#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Impromptu åŒ¹é…ç³»ç»Ÿæ¨¡å‹è®­ç»ƒè„šæœ¬

ç”¨äºè®­ç»ƒLDAä¸»é¢˜æ¨¡å‹å’Œå‘é‡åŒ–æ¨¡å‹
"""

import os
import sys
import json
import pickle
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.models.topic_modeling import LDATopicModel
from src.models.vector_matching import TopicVectorizer
from src.algorithms.tag_compatibility_analyzer import EnhancedCompatibilityAnalyzer

def train_topic_model(profiles_dir: str, output_dir: str):
    """è®­ç»ƒLDAä¸»é¢˜æ¨¡å‹"""
    print("ğŸ§  å¼€å§‹è®­ç»ƒLDAä¸»é¢˜æ¨¡å‹...")
    
    # è·å–æ‰€æœ‰æ¡£æ¡ˆæ–‡ä»¶
    profile_files = list(Path(profiles_dir).glob("*.json"))
    print(f"æ‰¾åˆ° {len(profile_files)} ä¸ªç”¨æˆ·æ¡£æ¡ˆ")
    
    if len(profile_files) == 0:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ç”¨æˆ·æ¡£æ¡ˆæ–‡ä»¶")
        return False
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = EnhancedCompatibilityAnalyzer()
    
    # è®­ç»ƒæ¨¡å‹
    profile_paths = [str(f) for f in profile_files]
    analyzer.train_models(profile_paths)
    
    # ä¿å­˜æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹ä¿å­˜é€»è¾‘
    print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä¿å­˜åˆ°: {output_dir}")
    return True

def batch_vectorize_users(profiles_dir: str, output_dir: str):
    """æ‰¹é‡å‘é‡åŒ–ç”¨æˆ·æ¡£æ¡ˆ"""
    print("ğŸ“Š å¼€å§‹æ‰¹é‡å‘é‡åŒ–ç”¨æˆ·æ¡£æ¡ˆ...")
    
    profile_files = list(Path(profiles_dir).glob("*.json"))
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = EnhancedCompatibilityAnalyzer()
    
    # è®­ç»ƒæ¨¡å‹
    profile_paths = [str(f) for f in profile_files]
    analyzer.train_models(profile_paths)
    
    # åˆ†ææ‰€æœ‰æ¡£æ¡ˆ
    analyzer.batch_analyze_profiles(profile_paths)
    
    # ä¿å­˜å‘é‡æ•°æ®
    os.makedirs(output_dir, exist_ok=True)
    vectors_file = os.path.join(output_dir, "all_users.json")
    
    print(f"âœ… ç”¨æˆ·å‘é‡åŒ–å®Œæˆï¼Œä¿å­˜åˆ°: {vectors_file}")
    return True

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("ğŸš€ Impromptu åŒ¹é…ç³»ç»Ÿæ¨¡å‹è®­ç»ƒ")
    print("================================")
    
    # é…ç½®è·¯å¾„
    profiles_dir = project_root / "data" / "raw" / "profiles"
    models_dir = project_root / "data" / "models"
    vectors_dir = project_root / "data" / "processed" / "user_vectors"
    
    print(f"ğŸ“ ç”¨æˆ·æ¡£æ¡ˆç›®å½•: {profiles_dir}")
    print(f"ğŸ“ æ¨¡å‹è¾“å‡ºç›®å½•: {models_dir}")
    print(f"ğŸ“ å‘é‡è¾“å‡ºç›®å½•: {vectors_dir}")
    print()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not profiles_dir.exists():
        print(f"âŒ é”™è¯¯: ç”¨æˆ·æ¡£æ¡ˆç›®å½•ä¸å­˜åœ¨ {profiles_dir}")
        return
    
    # è®­ç»ƒä¸»é¢˜æ¨¡å‹
    if not train_topic_model(str(profiles_dir), str(models_dir)):
        print("âŒ ä¸»é¢˜æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # æ‰¹é‡å‘é‡åŒ–
    if not batch_vectorize_users(str(profiles_dir), str(vectors_dir)):
        print("âŒ ç”¨æˆ·å‘é‡åŒ–å¤±è´¥")
        return
    
    print("\nğŸ‰ æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆï¼")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. è¿è¡Œæ¼”ç¤º: python scripts/demo/main.py")
    print("2. å¯åŠ¨API: bash scripts/setup/start_api.sh")

if __name__ == "__main__":
    main() 