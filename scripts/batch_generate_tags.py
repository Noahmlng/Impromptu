#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ‰¹é‡ç”Ÿæˆç”¨æˆ·æ ‡ç­¾è„šæœ¬
ä»æ•°æ®åº“è¯»å–ç”¨æˆ·æ•°æ®ï¼Œè°ƒç”¨æ ‡ç­¾ç”Ÿæˆç®—æ³•ï¼Œä¿å­˜åˆ°user_tagsè¡¨
"""

import json
import os
import sys
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import traceback
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥Supabaseå®¢æˆ·ç«¯
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    print("Warning: supabase package not available.")
    SUPABASE_AVAILABLE = False

# å¯¼å…¥æ ‡ç­¾ç”Ÿæˆç›¸å…³æ¨¡å—
from src.models.topic_modeling import topic_model
from src.algorithms.user_profile_analyzer import UserProfileAnalyzer

@dataclass
class TagGenerationResult:
    """æ ‡ç­¾ç”Ÿæˆç»“æœ"""
    user_id: str
    lda_tags: Dict[str, float]
    lda_metadata: Dict[str, Any]
    profile_analyzer_tags: Dict[str, float]
    profile_analyzer_metadata: Dict[str, Any]
    total_tags: int
    generation_time: float

@dataclass
class BatchStats:
    """æ‰¹é‡å¤„ç†ç»Ÿè®¡"""
    total_users: int = 0
    processed_users: int = 0
    failed_users: int = 0
    total_tags_generated: int = 0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class UserDataReader:
    """ç”¨æˆ·æ•°æ®è¯»å–å™¨"""
    
    def __init__(self, supabase: Client):
        self.supabase = supabase
    
    def get_all_users(self) -> List[str]:
        """è·å–æ‰€æœ‰ç”¨æˆ·ID"""
        result = self.supabase.table("user_profile").select("user_id").execute()
        return [row["user_id"] for row in result.data]
    
    def get_user_data(self, user_id: str) -> Dict[str, Any]:
        """è·å–å•ä¸ªç”¨æˆ·çš„å®Œæ•´æ•°æ®"""
        # è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
        profile_result = self.supabase.table("user_profile").select("*").eq("user_id", user_id).execute()
        if not profile_result.data:
            raise ValueError(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨")
        
        user_profile = profile_result.data[0]
        
        # è·å–ç”¨æˆ·å…ƒæ•°æ®
        metadata_result = self.supabase.table("user_metadata").select("*").eq("user_id", user_id).execute()
        user_metadata = metadata_result.data
        
        return {
            "user_profile": user_profile,
            "user_metadata": user_metadata
        }
    
    def build_user_text(self, user_data: Dict[str, Any]) -> tuple[str, str]:
        """ä»æ•°æ®åº“æ•°æ®æ„å»ºç”¨æˆ·æ–‡æœ¬æè¿°"""
        user_profile = user_data["user_profile"]
        user_metadata = user_data["user_metadata"]
        
        # æ„å»ºå®Œæ•´çš„ç”¨æˆ·æè¿°æ–‡æœ¬
        text_parts = []
        request_type = "all"
        
        # æ·»åŠ åŸºæœ¬ä¿¡æ¯
        text_parts.append(f"ç”¨æˆ·: {user_profile.get('display_name', '')}")
        text_parts.append(f"æ˜µç§°: {user_profile.get('nickname', '')}")
        
        # ä»å…ƒæ•°æ®ä¸­æå–ä¿¡æ¯
        for item in user_metadata:
            section_type = item.get("section_type", "")
            section_key = item.get("section_key", "")
            content = item.get("content", {})
            
            if isinstance(content, str):
                try:
                    content = json.loads(content)
                except:
                    continue
            
            # å¤„ç†ä¸åŒç±»å‹çš„å†…å®¹
            if section_type == "profile":
                if section_key == "name":
                    greeting = content.get("greeting", "")
                    if greeting:
                        text_parts.append(f"é—®å€™è¯­: {greeting}")
                
                elif section_key == "professional":
                    current_role = content.get("current_role", "")
                    responsibilities = content.get("responsibilities", [])
                    industry = content.get("industry", "")
                    if current_role:
                        text_parts.append(f"èŒä¸š: {current_role}")
                    if industry:
                        text_parts.append(f"è¡Œä¸š: {industry}")
                    if responsibilities:
                        text_parts.append(f"èŒè´£: {', '.join(responsibilities)}")
                
                elif section_key == "personal":
                    age_range = content.get("age_range", "")
                    location = content.get("location", "")
                    living_situation = content.get("living_situation", "")
                    if age_range:
                        text_parts.append(f"å¹´é¾„: {age_range}")
                    if location:
                        text_parts.append(f"åœ°ç‚¹: {location}")
                    if living_situation:
                        text_parts.append(f"å±…ä½çŠ¶å†µ: {living_situation}")
                
                elif section_key == "personality":
                    mbti_type = content.get("mbti_type", "")
                    personality_traits = content.get("personality_traits", [])
                    interests = content.get("interests", [])
                    values = content.get("values", [])
                    if mbti_type:
                        text_parts.append(f"MBTI: {mbti_type}")
                    if personality_traits:
                        text_parts.append(f"æ€§æ ¼ç‰¹ç‚¹: {', '.join(personality_traits)}")
                    if interests:
                        text_parts.append(f"å…´è¶£çˆ±å¥½: {', '.join(interests)}")
                    if values:
                        text_parts.append(f"ä»·å€¼è§‚: {', '.join(values)}")
                
                elif section_key == "qa_responses":
                    question = content.get("question", "")
                    answer = content.get("answer", "")
                    if question and answer:
                        text_parts.append(f"é—®: {question} ç­”: {answer}")
                
                elif section_key == "content":
                    post_content = content.get("content", "")
                    if post_content:
                        text_parts.append(f"å‘å¸ƒå†…å®¹: {post_content}")
            
            elif section_type == "user_request":
                req_type = content.get("request_type", "")
                description = content.get("description", "")
                if req_type:
                    request_type = req_type
                if description:
                    text_parts.append(f"ç”¨æˆ·éœ€æ±‚: {description}")
        
        user_text = ". ".join(text_parts)
        return user_text, request_type

class TagGenerator:
    """æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.profile_analyzer = UserProfileAnalyzer()
    
    def generate_tags(self, user_id: str, user_text: str, request_type: str) -> TagGenerationResult:
        """ä¸ºå•ä¸ªç”¨æˆ·ç”Ÿæˆæ ‡ç­¾"""
        start_time = datetime.now()
        
        # 1. ä½¿ç”¨LDAä¸»é¢˜å»ºæ¨¡ç”Ÿæˆæ ‡ç­¾
        lda_result = topic_model.extract_topics_and_tags(user_text, request_type)
        lda_tags = lda_result.extracted_tags
        lda_metadata = {
            "topics": [(int(tid), float(weight)) for tid, weight in lda_result.topics],
            "topic_keywords": {
                int(tid): [(word, float(weight)) for word, weight in words] 
                for tid, words in lda_result.topic_keywords.items()
            },
            "text_vector": [float(x) for x in lda_result.text_vector],
            "source_text_length": len(user_text)
        }
        
        # 2. ä½¿ç”¨ç”¨æˆ·ç”»åƒåˆ†æå™¨ç”Ÿæˆæ ‡ç­¾
        try:
            profile_result = self.profile_analyzer.analyze_user(user_id, user_text, request_type)
            profile_tags = profile_result.extracted_tags
            profile_metadata = {
                "tag_categories": profile_result.tag_categories,
                "total_score": profile_result.total_score,
                "profile_completeness": profile_result.profile_completeness,
                "request_type": profile_result.request_type
            }
        except Exception as e:
            print(f"  è­¦å‘Š: ç”¨æˆ·ç”»åƒåˆ†æå™¨å¤„ç† {user_id} æ—¶å‡ºé”™: {e}")
            profile_tags = {}
            profile_metadata = {"error": str(e)}
        
        generation_time = (datetime.now() - start_time).total_seconds()
        
        return TagGenerationResult(
            user_id=user_id,
            lda_tags=lda_tags,
            lda_metadata=lda_metadata,
            profile_analyzer_tags=profile_tags,
            profile_analyzer_metadata=profile_metadata,
            total_tags=len(lda_tags) + len(profile_tags),
            generation_time=generation_time
        )

class TagStorage:
    """æ ‡ç­¾å­˜å‚¨å™¨"""
    
    def __init__(self, supabase: Client):
        self.supabase = supabase
    
    def save_tags(self, result: TagGenerationResult) -> bool:
        """ä¿å­˜æ ‡ç­¾åˆ°æ•°æ®åº“"""
        try:
            tags_to_insert = []
            
            # ä¿å­˜LDAæ ‡ç­¾
            for tag_name, confidence in result.lda_tags.items():
                tags_to_insert.append({
                    "user_id": result.user_id,
                    "tag_source": "topic_modeling",
                    "tag_category": self._categorize_tag(tag_name),
                    "tag_name": tag_name,
                    "tag_value": tag_name,
                    "confidence_score": float(confidence),
                    "model_version": "v1.0",
                    "generation_context": json.dumps({
                        "generation_time": result.generation_time,
                        "algorithm": "LDA"
                    }, ensure_ascii=False),
                    "extraction_metadata": json.dumps(result.lda_metadata, ensure_ascii=False)
                })
            
            # ä¿å­˜ç”¨æˆ·ç”»åƒåˆ†æå™¨æ ‡ç­¾
            for tag_name, confidence in result.profile_analyzer_tags.items():
                tags_to_insert.append({
                    "user_id": result.user_id,
                    "tag_source": "user_profile_analyzer",
                    "tag_category": self._categorize_tag(tag_name),
                    "tag_name": tag_name,
                    "tag_value": tag_name,
                    "confidence_score": float(confidence),
                    "model_version": "v1.0",
                    "generation_context": json.dumps({
                        "generation_time": result.generation_time,
                        "algorithm": "ProfileAnalyzer"
                    }, ensure_ascii=False),
                    "extraction_metadata": json.dumps(result.profile_analyzer_metadata, ensure_ascii=False)
                })
            
            # åˆ†æ‰¹æ’å…¥ï¼Œé¿å…æ•°æ®è¿‡å¤§
            if tags_to_insert:
                batch_size = 50  # æ¯æ‰¹æœ€å¤š50ä¸ªæ ‡ç­¾
                for i in range(0, len(tags_to_insert), batch_size):
                    batch = tags_to_insert[i:i + batch_size]
                    self.supabase.table("user_tags").insert(batch).execute()
                    print(f"    æ’å…¥äº† {len(batch)} ä¸ªæ ‡ç­¾")
            
            return True
            
        except Exception as e:
            print(f"  âŒ ä¿å­˜æ ‡ç­¾å¤±è´¥: {e}")
            return False
    
    def _categorize_tag(self, tag_name: str) -> str:
        """ç®€å•çš„æ ‡ç­¾åˆ†ç±»é€»è¾‘"""
        tag_lower = tag_name.lower()
        
        # æ€§æ ¼ç›¸å…³
        personality_keywords = ["å†…å‘", "å¤–å‘", "å¼€æœ—", "é˜³å…‰", "å†·é™", "ç†æ€§", "æ„Ÿæ€§", "MBTI", "æ€§æ ¼"]
        if any(keyword in tag_lower for keyword in personality_keywords):
            return "personality"
        
        # å…´è¶£ç›¸å…³
        interest_keywords = ["å¥èº«", "è¿åŠ¨", "éŸ³ä¹", "è¯»ä¹¦", "æ—…è¡Œ", "æ‘„å½±", "æ¸¸æˆ", "ç”µå½±"]
        if any(keyword in tag_lower for keyword in interest_keywords):
            return "interests"
        
        # èŒä¸šç›¸å…³
        professional_keywords = ["å·¥ç¨‹å¸ˆ", "è®¾è®¡å¸ˆ", "æ•™ç»ƒ", "è€å¸ˆ", "åŒ»ç”Ÿ", "åˆ›ä¸š", "æŠ€æœ¯", "ç®¡ç†"]
        if any(keyword in tag_lower for keyword in professional_keywords):
            return "professional"
        
        # ç”Ÿæ´»æ–¹å¼
        lifestyle_keywords = ["å¥åº·", "æ—©ç¡", "è§„å¾‹", "ç”Ÿæ´»", "å±…ä½", "é¥®é£Ÿ"]
        if any(keyword in tag_lower for keyword in lifestyle_keywords):
            return "lifestyle"
        
        # ä»·å€¼è§‚
        values_keywords = ["è¯šå®", "æˆé•¿", "åˆ›æ–°", "åšæŒ", "å¸®åŠ©", "ç§¯æ"]
        if any(keyword in tag_lower for keyword in values_keywords):
            return "values"
        
        # é»˜è®¤åˆ†ç±»
        return "other"

class BatchTagGenerator:
    """æ‰¹é‡æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    def __init__(self, supabase_url: str, supabase_key: str):
        if not SUPABASE_AVAILABLE:
            raise ImportError("supabase package is required")
        
        self.supabase = create_client(supabase_url, supabase_key)
        self.data_reader = UserDataReader(self.supabase)
        self.tag_generator = TagGenerator()
        self.tag_storage = TagStorage(self.supabase)
        self.stats = BatchStats()
    
    def clear_existing_tags(self) -> bool:
        """æ¸…é™¤ç°æœ‰çš„æ‰€æœ‰æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰"""
        try:
            result = self.supabase.table("user_tags").delete().neq("id", "").execute()
            print(f"æ¸…é™¤äº†ç°æœ‰æ ‡ç­¾")
            return True
        except Exception as e:
            print(f"æ¸…é™¤ç°æœ‰æ ‡ç­¾å¤±è´¥: {e}")
            return False
    
    def process_single_user(self, user_id: str) -> bool:
        """å¤„ç†å•ä¸ªç”¨æˆ·"""
        try:
            print(f"\næ­£åœ¨å¤„ç†ç”¨æˆ·: {user_id}")
            
            # 1. è·å–ç”¨æˆ·æ•°æ®
            user_data = self.data_reader.get_user_data(user_id)
            
            # 2. æ„å»ºç”¨æˆ·æ–‡æœ¬
            user_text, request_type = self.data_reader.build_user_text(user_data)
            print(f"  - ç”¨æˆ·æ–‡æœ¬é•¿åº¦: {len(user_text)}")
            print(f"  - è¯·æ±‚ç±»å‹: {request_type}")
            print(f"  - æ–‡æœ¬é¢„è§ˆ: {user_text[:200]}...")
            
            # 3. ç”Ÿæˆæ ‡ç­¾
            result = self.tag_generator.generate_tags(user_id, user_text, request_type)
            print(f"  - LDAæ ‡ç­¾: {len(result.lda_tags)}ä¸ª")
            print(f"  - ç”»åƒåˆ†ææ ‡ç­¾: {len(result.profile_analyzer_tags)}ä¸ª")
            print(f"  - ç”Ÿæˆç”¨æ—¶: {result.generation_time:.2f}ç§’")
            
            # 4. ä¿å­˜æ ‡ç­¾
            if self.tag_storage.save_tags(result):
                print(f"  âœ… æˆåŠŸå¤„ç†: {user_id} (æ€»è®¡{result.total_tags}ä¸ªæ ‡ç­¾)")
                self.stats.total_tags_generated += result.total_tags
                return True
            else:
                print(f"  âŒ ä¿å­˜å¤±è´¥: {user_id}")
                return False
                
        except Exception as e:
            error_msg = f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.stats.errors.append(error_msg)
            return False
    
    def process_all_users(self, clear_existing: bool = False) -> BatchStats:
        """å¤„ç†æ‰€æœ‰ç”¨æˆ·"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆç”¨æˆ·æ ‡ç­¾...")
        
        # å¯é€‰ï¼šæ¸…é™¤ç°æœ‰æ ‡ç­¾
        if clear_existing:
            print("æ¸…é™¤ç°æœ‰æ ‡ç­¾...")
            self.clear_existing_tags()
        
        # è·å–æ‰€æœ‰ç”¨æˆ·
        try:
            user_ids = self.data_reader.get_all_users()
            self.stats.total_users = len(user_ids)
            print(f"æ‰¾åˆ° {self.stats.total_users} ä¸ªç”¨æˆ·")
        except Exception as e:
            self.stats.errors.append(f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {str(e)}")
            return self.stats
        
        # é€ä¸ªå¤„ç†ç”¨æˆ·
        for user_id in user_ids:
            try:
                if self.process_single_user(user_id):
                    self.stats.processed_users += 1
                else:
                    self.stats.failed_users += 1
            except Exception as e:
                self.stats.failed_users += 1
                self.stats.errors.append(f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"æ€»ç”¨æˆ·æ•°: {self.stats.total_users}")
        print(f"æˆåŠŸå¤„ç†: {self.stats.processed_users}")
        print(f"å¤„ç†å¤±è´¥: {self.stats.failed_users}")
        print(f"ç”Ÿæˆæ ‡ç­¾æ€»æ•°: {self.stats.total_tags_generated}")
        
        if self.stats.errors:
            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:")
            for error in self.stats.errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"  - {error}")
            if len(self.stats.errors) > 10:
                print(f"  ... è¿˜æœ‰ {len(self.stats.errors) - 10} ä¸ªé”™è¯¯")
        
        return self.stats

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è·å–Supabaseé…ç½®
    supabase_url = os.getenv("SUPABASE_URL") or "https://anxbbsrnjgmotxzysqwf.supabase.co"
    supabase_key = os.getenv("SUPABASE_ANON_KEY") or "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFueGJic3Juamdtb3R4enlzcXdmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTA0MDY0OTIsImV4cCI6MjA2NTk4MjQ5Mn0.a0t-pgH-Z2Fbs6JuMNWX8_kpqkQsBag3-COAUZVF6-0"
    
    try:
        # åˆ›å»ºæ‰¹é‡ç”Ÿæˆå™¨
        generator = BatchTagGenerator(supabase_url, supabase_key)
        
        # å¤„ç†æ‰€æœ‰ç”¨æˆ·ï¼ˆè®¾ç½®ä¸ºTrueä¼šæ¸…é™¤ç°æœ‰æ ‡ç­¾ï¼‰
        stats = generator.process_all_users(clear_existing=True)
        
        # è¿”å›çŠ¶æ€ç 
        return 0 if stats.failed_users == 0 else 1
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main()) 