#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ‰¹é‡å¯¼å…¥ç”¨æˆ·æ¡£æ¡ˆåˆ°æ•°æ®åº“è„šæœ¬
ä» data/raw/profiles/ æ–‡ä»¶å¤¹è¯»å–æ‰€æœ‰JSONæ–‡ä»¶å¹¶å¯¼å…¥åˆ°Supabaseæ•°æ®åº“
"""

import json
import os
import sys
import uuid
import random
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥Supabaseå®¢æˆ·ç«¯
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    print("Warning: supabase package not available. Will only generate SQL.")
    SUPABASE_AVAILABLE = False

@dataclass
class ImportStats:
    """å¯¼å…¥ç»Ÿè®¡"""
    total_files: int = 0
    success_count: int = 0
    error_count: int = 0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class ProfileImporter:
    """ç”¨æˆ·æ¡£æ¡ˆå¯¼å…¥å™¨"""
    
    def __init__(self, supabase_url: str = None, supabase_key: str = None):
        self.supabase = None
        if SUPABASE_AVAILABLE and supabase_url and supabase_key:
            self.supabase = create_client(supabase_url, supabase_key)
        
        # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨
        self.fake_emails = [
            "example{}@gmail.com", "test{}@outlook.com", "user{}@qq.com",
            "demo{}@163.com", "sample{}@sina.com"
        ]
        
        self.fake_phones = [
            "138{}8888", "139{}9999", "150{}0000", "188{}1111", "199{}2222"
        ]
        
        self.stats = ImportStats()
    
    def generate_fake_data(self, user_id: str) -> Dict[str, Any]:
        """ä¸ºç¼ºå¤±å­—æ®µç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        # ä»user_idæå–æ•°å­—ç”¨äºç”Ÿæˆä¸€è‡´çš„å‡æ•°æ®
        user_num = re.findall(r'\d+', user_id)
        seed = int(user_num[0]) if user_num else random.randint(1, 1000)
        
        # ä½¿ç”¨ç§å­ç¡®ä¿åŒä¸€ç”¨æˆ·ç”Ÿæˆç›¸åŒçš„å‡æ•°æ®
        random.seed(seed)
        
        return {
            "email": self.fake_emails[seed % len(self.fake_emails)].format(seed),
            "phone": self.fake_phones[seed % len(self.fake_phones)].format(str(seed).zfill(4)[:4]),
            "auth_user_id": str(uuid.uuid4()),
            "avatar_url": f"https://api.dicebear.com/7.x/avataaars/svg?seed={user_id}"
        }
    
    def extract_user_profile_data(self, user_id: str, profile_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»JSONæ¡£æ¡ˆæå–user_profileè¡¨éœ€è¦çš„æ•°æ®"""
        name_data = profile_data.get("profile", {}).get("name", {})
        
        # ç”Ÿæˆå‡æ•°æ®
        fake_data = self.generate_fake_data(user_id)
        
        return {
            "user_id": user_id,
            "display_name": name_data.get("display_name", user_id),
            "nickname": name_data.get("nickname", user_id.split("_")[-1]),
            "email": fake_data["email"],
            "phone": fake_data["phone"],
            "auth_user_id": None,  # è®¾ä¸ºNULLï¼Œä¹‹åå¯ä»¥å…³è”åˆ°çœŸå®è®¤è¯ç”¨æˆ·
            "avatar_url": fake_data["avatar_url"],
            "status": "active",
            "profile_version": 1
        }
    
    def extract_metadata_entries(self, user_id: str, profile_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»JSONæ¡£æ¡ˆæå–user_metadataè¡¨éœ€è¦çš„æ•°æ®"""
        entries = []
        profile_section = profile_data.get("profile", {})
        
        # å¤„ç†ä¸åŒçš„section_type
        sections_mapping = {
            "name": ("profile", "name", "nested_object"),
            "professional": ("profile", "professional", "nested_object"),
            "personal": ("profile", "personal", "nested_object"),
            "personality": ("profile", "personality", "nested_object"),
            "education": ("profile", "education", "nested_object"),
            "projects": ("profile", "projects", "nested_object"),
            "career_journey": ("profile", "career_journey", "nested_object"),
            "expertise_areas": ("profile", "expertise_areas", "nested_object"),
            "lifestyle": ("profile", "lifestyle", "nested_object"),
        }
        
        # å¤„ç†åŸºç¡€sections
        for section_key, (section_type, db_section_key, data_type) in sections_mapping.items():
            if section_key in profile_section:
                entries.append({
                    "user_id": user_id,
                    "section_type": section_type,
                    "section_key": db_section_key,
                    "data_type": data_type,
                    "content": json.dumps(profile_section[section_key], ensure_ascii=False),
                    "display_order": len(entries) + 1,
                    "is_active": True,
                    "metadata": "{}"
                })
        
        # å¤„ç†ç¤¾äº¤åª’ä½“
        if "social_media" in profile_section:
            social_data = profile_section["social_media"]
            for platform, platform_data in social_data.items():
                entries.append({
                    "user_id": user_id,
                    "section_type": "profile",
                    "section_key": "social_media",
                    "data_type": "social_link",
                    "content": json.dumps({
                        "platform": platform,
                        **platform_data
                    }, ensure_ascii=False),
                    "display_order": len(entries) + 1,
                    "is_active": True,
                    "metadata": json.dumps({"platform": platform}, ensure_ascii=False)
                })
        
        # å¤„ç†å†…å®¹å‘å¸ƒ
        if "content" in profile_section:
            content_data = profile_section["content"]
            if "posts" in content_data:
                for i, post in enumerate(content_data["posts"]):
                    entries.append({
                        "user_id": user_id,
                        "section_type": "profile", 
                        "section_key": "content",
                        "data_type": "content_post",
                        "content": json.dumps(post, ensure_ascii=False),
                        "display_order": i + 1,
                        "is_active": True,
                        "metadata": json.dumps({"platform": post.get("platform", "unknown")}, ensure_ascii=False)
                    })
        
        # å¤„ç†QAé—®ç­”
        if "qa_responses" in profile_section:
            for i, qa in enumerate(profile_section["qa_responses"]):
                entries.append({
                    "user_id": user_id,
                    "section_type": "profile",
                    "section_key": "qa_responses", 
                    "data_type": "qa_pair",
                    "content": json.dumps(qa, ensure_ascii=False),
                    "display_order": i + 1,
                    "is_active": True,
                    "metadata": "{}"
                })
        
        # å¤„ç†è”ç³»åå¥½
        if "contact_preferences" in profile_section:
            entries.append({
                "user_id": user_id,
                "section_type": "profile",
                "section_key": "contact_preferences",
                "data_type": "nested_object",
                "content": json.dumps(profile_section["contact_preferences"], ensure_ascii=False),
                "display_order": len(entries) + 1,
                "is_active": True,
                "metadata": "{}"
            })
        
        # å¤„ç†ç”¨æˆ·è¯·æ±‚
        if "user_request" in profile_data:
            entries.append({
                "user_id": user_id,
                "section_type": "user_request",
                "section_key": "main_request", 
                "data_type": "nested_object",
                "content": json.dumps(profile_data["user_request"], ensure_ascii=False),
                "display_order": 1,
                "is_active": True,
                "metadata": json.dumps({"request_type": profile_data["user_request"].get("request_type", "æœªçŸ¥")}, ensure_ascii=False)
            })
        
        # å¤„ç†å…ƒæ•°æ®
        if "metadata" in profile_data:
            entries.append({
                "user_id": user_id,
                "section_type": "metadata",
                "section_key": "profile_metadata",
                "data_type": "nested_object", 
                "content": json.dumps(profile_data["metadata"], ensure_ascii=False),
                "display_order": 1,
                "is_active": True,
                "metadata": "{}"
            })
        
        return entries
    
    def load_profile_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å•ä¸ªæ¡£æ¡ˆæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.stats.errors.append(f"Failed to load {file_path}: {str(e)}")
            return None
    
    def insert_user_profile(self, profile_data: Dict[str, Any]) -> bool:
        """æ’å…¥ç”¨æˆ·åŸºæœ¬ä¿¡æ¯"""
        try:
            if self.supabase:
                print(f"  - æ’å…¥ç”¨æˆ·æ¡£æ¡ˆ: {profile_data.get('user_id')}")
                result = self.supabase.table("user_profile").insert(profile_data).execute()
                print(f"  - æ’å…¥æˆåŠŸï¼Œå“åº”: {len(result.data) if result.data else 0} æ¡è®°å½•")
                return True
            else:
                # ç”ŸæˆSQL
                columns = ", ".join(profile_data.keys())
                values = ", ".join([f"'{v}'" if isinstance(v, str) else str(v) for v in profile_data.values()])
                print(f"INSERT INTO user_profile ({columns}) VALUES ({values});")
                return True
        except Exception as e:
            error_msg = f"Failed to insert user_profile for {profile_data.get('user_id')}: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.stats.errors.append(error_msg)
            return False
    
    def insert_user_metadata(self, metadata_entries: List[Dict[str, Any]]) -> bool:
        """æ’å…¥ç”¨æˆ·å…ƒæ•°æ®"""
        try:
            if self.supabase:
                if metadata_entries:
                    print(f"  - æ’å…¥å…ƒæ•°æ®: {len(metadata_entries)} æ¡è®°å½•")
                    result = self.supabase.table("user_metadata").insert(metadata_entries).execute()
                    print(f"  - å…ƒæ•°æ®æ’å…¥æˆåŠŸï¼Œå“åº”: {len(result.data) if result.data else 0} æ¡è®°å½•")
                return True
            else:
                # ç”ŸæˆSQL
                for entry in metadata_entries:
                    columns = ", ".join(entry.keys())
                    values = ", ".join([f"'{v}'" if isinstance(v, str) else str(v) for v in entry.values()])
                    print(f"INSERT INTO user_metadata ({columns}) VALUES ({values});")
                return True
        except Exception as e:
            user_id = metadata_entries[0].get('user_id', 'unknown') if metadata_entries else 'unknown'
            error_msg = f"Failed to insert user_metadata for {user_id}: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.stats.errors.append(error_msg)
            return False
    
    def import_single_profile(self, file_path: str) -> bool:
        """å¯¼å…¥å•ä¸ªç”¨æˆ·æ¡£æ¡ˆ"""
        # ä»æ–‡ä»¶åæå–user_id
        filename = os.path.basename(file_path)
        user_id = filename.replace('.json', '')
        
        print(f"æ­£åœ¨å¤„ç†: {user_id}")
        
        # åŠ è½½æ–‡ä»¶
        profile_data = self.load_profile_file(file_path)
        if not profile_data:
            return False
        
        # æå–æ•°æ®
        user_profile_data = self.extract_user_profile_data(user_id, profile_data)
        metadata_entries = self.extract_metadata_entries(user_id, profile_data)
        
        # æ’å…¥æ•°æ®åº“
        profile_success = self.insert_user_profile(user_profile_data)
        metadata_success = self.insert_user_metadata(metadata_entries)
        
        if profile_success and metadata_success:
            print(f"âœ… æˆåŠŸå¯¼å…¥: {user_id} (æ¡£æ¡ˆ + {len(metadata_entries)}æ¡å…ƒæ•°æ®)")
            return True
        else:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {user_id}")
            return False
    
    def import_all_profiles(self, profiles_dir: str = "data/raw/profiles") -> ImportStats:
        """æ‰¹é‡å¯¼å…¥æ‰€æœ‰ç”¨æˆ·æ¡£æ¡ˆ"""
        print(f"å¼€å§‹æ‰¹é‡å¯¼å…¥ç”¨æˆ·æ¡£æ¡ˆ...")
        print(f"ç›®å½•: {profiles_dir}")
        
        if not os.path.exists(profiles_dir):
            self.stats.errors.append(f"ç›®å½•ä¸å­˜åœ¨: {profiles_dir}")
            return self.stats
        
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶
        json_files = [f for f in os.listdir(profiles_dir) if f.endswith('.json')]
        self.stats.total_files = len(json_files)
        
        print(f"æ‰¾åˆ° {self.stats.total_files} ä¸ªJSONæ–‡ä»¶")
        
        # é€ä¸ªå¤„ç†æ–‡ä»¶
        for filename in sorted(json_files):
            file_path = os.path.join(profiles_dir, filename)
            
            try:
                if self.import_single_profile(file_path):
                    self.stats.success_count += 1
                else:
                    self.stats.error_count += 1
            except Exception as e:
                self.stats.error_count += 1
                self.stats.errors.append(f"Unexpected error processing {filename}: {str(e)}")
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆ!")
        print(f"æ€»æ–‡ä»¶æ•°: {self.stats.total_files}")
        print(f"æˆåŠŸ: {self.stats.success_count}")
        print(f"å¤±è´¥: {self.stats.error_count}")
        
        if self.stats.errors:
            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:")
            for error in self.stats.errors:
                print(f"  - {error}")
        
        return self.stats

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è·å–Supabaseé…ç½®
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_ANON_KEY")
    
    if not supabase_url or not supabase_key:
        print("Warning: SUPABASE_URL æˆ– SUPABASE_ANON_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("å°†ä»¥SQLç”Ÿæˆæ¨¡å¼è¿è¡Œ...")
    
    # åˆ›å»ºå¯¼å…¥å™¨
    importer = ProfileImporter(supabase_url, supabase_key)
    
    # æ‰§è¡Œå¯¼å…¥
    stats = importer.import_all_profiles()
    
    # è¿”å›çŠ¶æ€ç 
    return 0 if stats.error_count == 0 else 1

if __name__ == "__main__":
    exit(main()) 